import os  # Biblioteca para manipula√ß√£o do sistema operacional (n√£o usada neste c√≥digo).
import streamlit as st  # Biblioteca para criar interfaces de aplicativos web.

st.set_page_config(
    page_title="MedIA",  # Nome exibido na aba do navegador.
    page_icon="ü§ñ",      # √çcone exibido ao lado do t√≠tulo da p√°gina.
    layout="centered",       # Layout da p√°gina (pode ser 'centered' ou 'wide').
)

# HTML e JavaScript para o sistema de part√≠culas
particles_html = """
<div id="particles-js" style="position: fixed; width: 100%; height: 100%; z-index: -1;"></div>
<script src="https://cdn.jsdelivr.net/npm/particles.js"></script>
<script>
    particlesJS("particles-js", {
        "particles": {
            "number": {
                "value": 100,
                "density": { "enable": true, "value_area": 800 }
            },
            "color": { "value": "#ffffff" },
            "shape": {
                "type": "circle",
                "stroke": { "width": 0, "color": "#000000" },
                "polygon": { "nb_sides": 5 },
            },
            "opacity": {
                "value": 0.5,
                "random": false,
                "anim": { "enable": false, "speed": 1, "opacity_min": 0.1, "sync": false }
            },
            "size": {
                "value": 5,
                "random": true,
                "anim": { "enable": false, "speed": 40, "size_min": 0.1, "sync": false }
            },
            "line_linked": {
                "enable": true,
                "distance": 150,
                "color": "#ffffff",
                "opacity": 0.4,
                "width": 1
            },
            "move": {
                "enable": true,
                "speed": 6,
                "direction": "none",
                "random": false,
                "straight": false,
                "out_mode": "out",
                "bounce": false,
                "attract": { "enable": false, "rotateX": 600, "rotateY": 1200 }
            }
        },
        "interactivity": {
            "detect_on": "canvas",
            "events": {
                "onhover": { "enable": true, "mode": "repulse" },
                "onclick": { "enable": true, "mode": "push" },
                "resize": true
            },
            "modes": {
                "grab": { "distance": 400, "line_linked": { "opacity": 1 } },
                "bubble": { "distance": 400, "size": 40, "duration": 2, "opacity": 8, "speed": 3 },
                "repulse": { "distance": 200, "duration": 0.4 },
                "push": { "particles_nb": 4 },
                "remove": { "particles_nb": 2 }
            }
        },
        "retina_detect": true
    });
</script>
"""

# Importa√ß√µes do LangChain, usadas para criar cadeias de processamento de linguagem natural.
from langchain.chains import LLMChain
from langchain.prompts import (
    ChatPromptTemplate,  # Modelo de prompt para intera√ß√µes baseadas em mensagens de chat.
    HumanMessagePromptTemplate,  # Modelo para representar mensagens de entrada do usu√°rio.
    MessagesPlaceholder,  # Placeholder para mensagens do hist√≥rico.
)
from langchain.schema import SystemMessage  # Representa mensagens de sistema em conversas.
from langchain.chains.conversation.memory import ConversationBufferWindowMemory  # Gerencia o hist√≥rico de conversas.
from langchain_groq import ChatGroq  # Integra√ß√£o com o modelo LLM Groq.



# Fun√ß√£o principal do aplicativo.
def main():
    """
    Ponto de entrada principal do aplicativo.

    Configura a interface, inicializa o modelo LLM Groq, gerencia o hist√≥rico de conversas
    e processa a intera√ß√£o do usu√°rio com o chatbot MedIA.
    """

    # Obt√©m a chave de API do modelo Groq a partir dos segredos configurados no Streamlit.
    groq_api_key = st.secrets["GROQ_API_KEY"]
    # Define o modelo a ser usado.
    model = 'llama3-8b-8192'

    # Inicializa o cliente Groq com a chave de API e o modelo especificado.
    groq_chat = ChatGroq(groq_api_key=groq_api_key, model_name=model)

    # Configura o t√≠tulo e a descri√ß√£o do aplicativo.
    st.title("MedIA")
    st.write(
        """
        Seja bem-vindo ao MedIA! \n\n
        Sou um sistema de intelig√™ncia artificial treinado para auxiliar na an√°lise de sintomas 
        e direcionar voc√™ para o caminho certo. Baseado em suas respostas, tentarei tra√ßar um panorama 
        do que pode estar acontecendo.
        """
    )

    # Mensagem de sistema usada para configurar o comportamento do modelo.
    system_prompt = (
        "Voc√™ √© um especialista em diagn√≥sticos m√©dicos. Baseado nos sintomas apresentados pelo usu√°rio, "
        "personalize um poss√≠vel diagn√≥stico. Sugira ao paciente que ele responda todas as perguntas sem exce√ß√£o. "
        "N√£o d√™ a resposta enquanto ele n√£o responder todas as perguntas. Ap√≥s ele responder as 10 perguntas, "
        "voc√™ pode dar o diagn√≥stico e recomendar poss√≠veis exames que um m√©dico pediria. "
        "Se ele perguntar os sintomas de alguma doen√ßa, d√™ a resposta imediatamente nesse caso, sem fazer perguntas. "
        "Receite alguns rem√©dios b√°sicos que n√£o precisam ser orientados por um profissional e recomende alguns exames. "
        "Coloque todas as doen√ßas relacionadas poss√≠veis. Fa√ßa sempre 10 perguntas muito √∫teis, nem menos nem mais que isso. "
        "Fa√ßa 1 pergunta de cada vez. Quando estiver acabando as perguntas, avise o paciente. "
        "Se o usu√°rio disser que levou tiro ou golpe de faca, oriente-o a ligar para o 190 e pedir ajuda imediata."
    )

    # Comprimento m√°ximo do hist√≥rico de conversas.
    conversational_memory_length = 50000

    # Inicializa a mem√≥ria da conversa no estado da sess√£o, se ainda n√£o estiver configurada.
    if 'memory' not in st.session_state:
        st.session_state.memory = ConversationBufferWindowMemory(
            k=conversational_memory_length, memory_key="chat_history", return_messages=True
        )

    # Inicializa o hist√≥rico de mensagens do usu√°rio e do chatbot, se n√£o existir.
    if 'history' not in st.session_state:
        st.session_state.history = []

    # Adiciona estilos customizados para a interface do chat.
    st.markdown(
        """
        <style>
            .chat-input-container {
                position: fixed;
                bottom: 0;
                left: 50%;
                transform: translateX(-50%);
                width: 60%;
                z-index: 1000;
                background-color: #f0f2f6;
                padding: 10px;
                border-top: 1px solid #ddd;
            }
            #chat-history {
                height: calc(100vh - 150px);
                overflow-y: auto;
                padding-bottom: 60px;
            }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Exibe o hist√≥rico da conversa na interface.
    st.subheader("Respostas do MedIA")
    if st.session_state.history:
        st.markdown(
            f"""
            <div id="chat-history" style="display: flex; flex-direction: column;">
                {"<hr>".join(st.session_state.history)}
            </div>
            """, 
            unsafe_allow_html=True
        )

    # Campo de entrada para o usu√°rio digitar os sintomas.
    user_input = st.chat_input(
        "Digite seus sintomas",
        key='user_input'
    )

    if user_input:  # Se o usu√°rio forneceu uma entrada:
        # Adiciona a entrada do usu√°rio ao hist√≥rico.
        st.session_state.history.append(f"<div class='message user-message'><strong>Voc√™:</strong> {user_input}</div>")

        # Cria o prompt do chatbot usando os templates de mensagens.
        prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessage(content=system_prompt),  # Mensagem de sistema inicial.
                MessagesPlaceholder(variable_name="chat_history"),  # Hist√≥rico de conversas.
                HumanMessagePromptTemplate.from_template("{human_input}"),  # Entrada do usu√°rio.
            ]
        )

        # Configura a cadeia de intera√ß√£o com o modelo LLM.
        conversation = LLMChain(
            llm=groq_chat,  # Cliente Groq para intera√ß√µes.
            prompt=prompt,  # Prompt configurado.
            verbose=False,  # Sem logs detalhados.
            memory=st.session_state.memory,  # Mem√≥ria da conversa.
        )

        # Obt√©m a resposta do modelo para a entrada do usu√°rio.
        response = conversation.predict(human_input=user_input)

        # Adiciona a resposta do modelo ao hist√≥rico.
        st.session_state.history.append(f"<div class='message ai-message'><strong>MedIA:</strong> {response}</div>")
        # Atualiza a interface para refletir o novo estado.
        st.rerun()

    # Script para rolar automaticamente o hist√≥rico de mensagens ao final.
    st.markdown(
        """
        <script>
            document.addEventListener('DOMContentLoaded', function() {
                const chatHistory = document.getElementById('chat-history');
                const observer = new MutationObserver(() => {
                    chatHistory.scrollTop = chatHistory.scrollHeight;
                });
                if (chatHistory) {
                    observer.observe(chatHistory, { childList: true });
                    chatHistory.scrollTop = chatHistory.scrollHeight;
                }
            });
        </script>
        """,
        unsafe_allow_html=True
    )

# Ponto de entrada do aplicativo.
if __name__ == "__main__":
    main()
